{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbec4edf-af2f-4a7b-867d-720c2e427ffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Lab 5\n",
    "- **Name:** Shy Ohev Zion\n",
    "- **ID:** 318783479"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766ad46-ebf4-4b61-abeb-6826e982cc82",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "**This lab introduced us to:**\n",
    "- the MNIST dataset and the pytorch module\n",
    "- Importance of determinism and reproducibility\n",
    "- conversion from numpy ndarrays to pytorch tensors and vice versa\n",
    "- building classification models using previously-learned functions/concepts:\n",
    "    - convolution (actually cross-correlation)\n",
    "    - matrix multiplication (linear \"fully connected\" layers)\n",
    "    - the ReLu function\n",
    "    - the tanh function\n",
    "    - the softmax function\n",
    "    - the argmax function\n",
    "\n",
    "**In the following report** I've built several models as said above and 'tested' each one (results were random as none of the models were trained):\n",
    "- a single linear layer model\n",
    "- 3 fully connected (linear) layers, with ReLu as an activation function (without it the model is equivalent to a single linear layer model)\n",
    "- a simple convolution model\n",
    "- the LeNet architecture, one of the earliest CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604253fa-9bc0-4520-8eb5-477a292f3d93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports, Configurations and Function Definitions (relevant for all sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa4d540-2216-4bee-babe-8b37252dcc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47a556-8f6e-4001-9284-4308c204b07c",
   "metadata": {},
   "source": [
    "Deterministic Environment Configuration and Random Generation Seed Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5ac043-d999-4652-9058-45f210199f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed = 1\n",
    "np_rng = np.random.default_rng(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch_rng_cpu = torch.Generator().manual_seed(seed)\n",
    "torch_rng_gpu = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0155f-ef10-413c-ae57-c22abdcc69a0",
   "metadata": {},
   "source": [
    "Printing fuction useful in all following code segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7df0a01-8c9a-48e0-b726-285be523ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output_values(model_output):\n",
    "    softmax_output = F.softmax(model_output, dim=-1)\n",
    "    print(f\"output:\\n{model_output}\\n\")\n",
    "    print(f\"output with softmax:\\n{softmax_output}\\n\")\n",
    "    print(f\"sum (no softmax): {model_output.sum().item()}\")\n",
    "    print(f\"sum (with softmax): {softmax_output.sum().item()}\")\n",
    "    print(f\"predicted digit (no softmax): {model_output.argmax()}\")\n",
    "    print(f\"predicted digit (with softmax): {softmax_output.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ca50f-6c7b-44a7-ad45-e95d1d0dfe94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### importing the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b95df85-b7a0-4fa9-b2d8-07e450ed0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=Compose((ToTensor(), Lambda(lambda x: x.squeeze() / 255.0))),\n",
    ")\n",
    "\n",
    "trainset_len, height, width = trainset.data.shape\n",
    "num_classes = len(trainset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa0cbc-de96-42ff-adbe-29c331cbc9d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Preparatory Work\n",
    "no preparatory work was required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e4579-e20e-4bb2-ba8f-7cbad1905937",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Lab Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b19445-1a04-48d9-af9d-9c6aede4a8f6",
   "metadata": {},
   "source": [
    "Visualizing an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bade4fb6-2537-4ae2-b281-229d8762b162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'The Number 3')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np_rng.integers(trainset_len)\n",
    "random_image, random_target = trainset[idx]\n",
    "plt.imshow(random_image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"The Number {random_target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2ee2c-bf32-42a8-8a0c-81c4a0d1d33f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing and Testing a Single Layer Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadb0423-391e-4de0-be35-e0ecf004b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, in_features_size, out_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=in_features_size, out_features=out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.linear(x.view(-1, math.prod(x.shape))))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855cf15d-6354-427a-ad3a-bd616436ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model1(height * width, num_classes)\n",
    "output = model(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4df87f9-a6e6-4b2a-a356-b038566c5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[0.0305, 0.0016, 0.0274, 0.0146, 0.0000, 0.0321, 0.0013, 0.0092, 0.0000,\n",
      "         0.0132]])\n",
      "\n",
      "output with softmax:\n",
      "tensor([[0.1018, 0.0989, 0.1014, 0.1002, 0.0987, 0.1019, 0.0988, 0.0996, 0.0987,\n",
      "         0.1000]])\n",
      "\n",
      "sum (no softmax): 0.1299283802509308\n",
      "sum (with softmax): 1.0\n",
      "predicted digit (no softmax): 5\n",
      "predicted digit (with softmax): 5\n"
     ]
    }
   ],
   "source": [
    "print_output_values(output.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d9ccb-33ef-4117-ab30-8db38fc206c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82d273-a02b-44b5-8747-1f12a8a9dc3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing and Testing a 3 Layer Fully Connected Model:\n",
    "- first hidden layer of size 128\n",
    "- second hidden layer of size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7a2b4f-00b7-4d63-a40d-3d17f91be644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, in_features_size, out_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_features_size, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x.view(-1, math.prod(x.shape))))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        y = F.relu(self.fc3(h2))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b600a0cd-dc10-409d-b0b9-fbb03dfa0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0752, 0.0331, 0.0000, 0.0137, 0.0280, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "output with softmax:\n",
      "tensor([[0.0985, 0.0985, 0.0985, 0.1062, 0.1018, 0.0985, 0.0998, 0.1013, 0.0985,\n",
      "         0.0985]])\n",
      "\n",
      "sum (no softmax): 0.14995284378528595\n",
      "sum (with softmax): 1.0\n",
      "predicted digit (no softmax): 3\n",
      "predicted digit (with softmax): 3\n"
     ]
    }
   ],
   "source": [
    "model2 = Model2(height * width, num_classes)\n",
    "output = model2(random_image)\n",
    "print_output_values(output.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94d09e-6d17-4137-a794-121585d347a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb3793a-24cf-43e3-af3e-a085a76d9d08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing and Testing a Model With Convolution Layers:\n",
    "- first layer is a convolution layer with 8 convolution kernels of 3x3\n",
    "- second layer is a pooling layer with max-pooling kernels of 2x2 with stride 2 (meaning no intersection between pools)\n",
    "- third layer is the fully connected layer, with input size of $\\frac{8*(H-2)*(W-2)}{2^2}$ (where $H, W$ are the input's dimensions) and with a ReLu activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca275771-fa15-4f26-a2b5-c0cebe9d306d",
   "metadata": {},
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65ee7417-0fed-4279-8d53-11a66cf7e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self, in_height, in_width, out_size):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=8 * (in_height - 2) * (in_width - 2) // (2 ** 2),\n",
    "            out_features=out_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.conv(x)\n",
    "        h2 = self.pool(h1)\n",
    "        y = F.relu(self.linear(h2.view(-1, math.prod(h2.shape))))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f774147-8d28-4e73-8a72-84a417382a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[0.0783, 0.0451, 0.0000, 0.0000, 0.0088, 0.0000, 0.0857, 0.0000, 0.0832,\n",
      "         0.1537]])\n",
      "\n",
      "output with softmax:\n",
      "tensor([[0.1032, 0.0998, 0.0954, 0.0954, 0.0963, 0.0954, 0.1040, 0.0954, 0.1037,\n",
      "         0.1113]])\n",
      "\n",
      "sum (no softmax): 0.4546310305595398\n",
      "sum (with softmax): 1.0\n",
      "predicted digit (no softmax): 9\n",
      "predicted digit (with softmax): 9\n"
     ]
    }
   ],
   "source": [
    "conv_ready_image = random_image[np.newaxis, np.newaxis, :]\n",
    "model3 = Model3(height, width, num_classes)\n",
    "output = model3(conv_ready_image)\n",
    "print_output_values(output.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203efa5-332b-4e54-9213-6036bd57cf4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Final Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48326cb0-dda2-47f5-a5aa-01394105f5e5",
   "metadata": {},
   "source": [
    "### Building the LeNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d057e2-135a-48ca-9d86-2fb55c5bd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=6, kernel_size=5, padding=2\n",
    "        )  # (6,28,28) output shape\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # (6, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5\n",
    "        )  # (16, 10, 10)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # (16, 5, 5)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=120, kernel_size=5\n",
    "        )  # (120, 1, 1)\n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)  # (80)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)  # (10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.conv1(x).tanh()\n",
    "        h2 = self.pool1(h1)\n",
    "        h3 = self.conv2(h2).tanh()\n",
    "        h4 = self.pool2(h3)\n",
    "        h5 = self.conv3(h4).tanh()\n",
    "        h6 = self.fc1(h5.view(-1, math.prod(h5.shape))).tanh()\n",
    "        y = self.fc2(h6)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd870523-75bf-4876-8620-a64874dfea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "tensor([[-0.1041,  0.0088, -0.0528,  0.0469, -0.0183, -0.0684, -0.0887,  0.0995,\n",
      "         -0.0178,  0.0511]])\n",
      "\n",
      "output with softmax:\n",
      "tensor([[0.0912, 0.1021, 0.0960, 0.1061, 0.0994, 0.0946, 0.0926, 0.1118, 0.0995,\n",
      "         0.1066]])\n",
      "\n",
      "sum (no softmax): -0.14386633038520813\n",
      "sum (with softmax): 0.9999999403953552\n",
      "predicted digit (no softmax): 7\n",
      "predicted digit (with softmax): 7\n"
     ]
    }
   ],
   "source": [
    "lenet_model = LeNet()\n",
    "output = lenet_model(conv_ready_image)\n",
    "print_output_values(output.detach().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
